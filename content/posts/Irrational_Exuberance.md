+++
title =  "#1 Irrational Exuberance"
date = 2019-07-26T19:42:20-07:00
tags = []
featured_image = ""
description = ""
+++

## Irrational Exuberance

Artificial Intelligence has disrupted industries like finance, e-commerce, advertising, and is poised to disrupt many more. While I'm wholly excited about the possibilities of deploying A.I. in your organization, it's important to establish the context for our discussion. And for that, we need to get off the hype train, and approach the subject rationally.

*A.I. solutionism* is a philosophy that given enough data, Machine Learning algorithms can solve all of our problems. It is prevalent in the business and research community, as evident by thousands of "A.I. startups" created everyday. The last batch of Y-Combinator's online program had  This exuberance has spread over to the media and general public. It has creatde fear and angst: everything from machines taking over everyone's jobs to doomsday scenarios. However, this does not reflect the real-world complexity of deploying machine learning systems, and sets unrealistic expectations of what A.I. can achieve, at least in the coming decade.

There are limits to what A.I can do. Here's where solutionism mindset fails to account for: 

1. A.I. systems need **high-quality data to function, and lots of it**. Most SMEs currently do not have the data collection, processing or talent to support advanced Machine Learning,

2. AI systems are very **susceptible to adversarial attacks**. Malicious entities can force A.I. to make wrong predictions or behave in a certain way.

3. The Solutionism mindset does not respect the important **A.I safety and ethical principles**. Deploying A.I. in complex systems like Government, Healthcare and Judiciary can have unforeseen effects on society and has to be approached with utmost caution.

Outside of the business and research community, among the general public, there seems to be a pervading distrust in A.I. It's not unwarranted when we consider these cases:

- *The IBM Watson for Oncology* program was started to help doctors treat cancer. Even though it delivered the best algorithmic recommendations, human experts found it difficult to trust the machine. As a result, the program was discontinued. 

- In the legal domain, A.I. systems have been developed to help judges make more data-backed decisions in court. However, the A.I. system was found to amplify racial discrimination, resulting in major backlash from the public. In recruitment decisions, A.I. systems where found to heavily favor men.

- Valuable models like Deep Learning remain a black box. By changing one pixel in a picture of a lion, scientists were able to make the model label the picture as a library (with 99.9% confidence rating)! Cases like these have left researchers perplexed.

A.I. is not a hammer that an organization can use to pound at any problem. It's a hammer that is very powerful, expensive and has serious risks. So it's important to think clearly about where and how it can be used, and that's what the rest of the posts in this series tackle.
